{
  
    
        "post0": {
            "title": "Machine Learning Quiz 2 Practice",
            "content": "import numpy as np import pandas as pd import torch . . Maths for ML . Given a vector $ epsilon$, we can calculate $ sum epsilon_{i}^{2}$ using $ epsilon^{T} epsilon$ | # As per the convention we take epsilon to be a 2D column vector y = np.array([1.3, 2.5, 6.4, 8.1, 9.0]).reshape(-1, 1) y_hat = np.array([1.5, 2.0, 5.9, 8.5, 9.0]).reshape(-1, 1) epsilon = np.abs(y - y_hat) epsilon_square_sum1 = np.sum(epsilon**2) epsilon_square_sum2 = (epsilon.T @ epsilon).item() assert np.allclose(epsilon_square_sum1, epsilon_square_sum2) . . üëç works! . $(AB)^{T} = B^{T}A^{T}$ | A = np.random.randn(50, 10) B = np.random.randn(10, 20) ab_t = (A @ B).T b_t_a_t = B.T @ A.T assert np.allclose(ab_t, b_t_a_t) . . üôÑ Knew it already! . For a scalar $s$, $s = s^{T}$ | Derivative of scalar $s$ with respect to (yes!, I wrote wrt as full here üòÅ) vector $ theta$ $$ theta = begin{bmatrix} theta_{1} theta_{2} vdots theta{n} end{bmatrix}$$ $$ frac{ partial s}{ partial theta} = begin{bmatrix} frac{ partial s}{ partial theta_{1}} frac{ partial s}{ partial theta_{2}} frac{ partial s}{ partial theta_{3}} vdots frac{ partial s}{ partial theta_{n}} end{bmatrix} $$ | If $A$ is a matrix and $ theta$ is a vector, and $A theta$ is a scalar. Then $$ frac{ partial A theta}{ partial theta} = A^{T} $$ | ü§î Taking some similarity with $a theta$, where both $a$ and $ theta$ are scalar, I have an idea that it would be A. But shape of gradient would be $N times 1$, so $A^{T}$ is my guess before starting any calculations. . N = 20 # as A $ theta$ is scalar, so A.shape[0] should be 1. A = torch.randn((1, N)) theta = torch.randn((N, 1), requires_grad=True) scalar = A @ theta scalar.backward() assert torch.allclose(theta.grad, A.T) . . üëç all good . Assume $Z$ is a matrix of form $X^{T}X$, then $$ frac{ partial ( theta^{T}Z theta)}{ partial theta} = 2Z^{T} theta$$ | ü§î Let me again make a good guess before any calculation, if $ theta$ and $Z$ are both scaler, then the derivative would look like $2Z theta$. So my guess would $2Z theta$, which is equal to $2Z^{T} theta$ as both are $Z$ is symmetric. . X = torch.randn((N, N)) Z = X.T @ X theta = torch.randn((N, 1), requires_grad=True) scalar = theta.T @ Z @ theta scalar.backward() assert torch.allclose(theta.grad, 2 * Z.T @ theta) . . üëç good . Let&#39;s skip over the content of Rank topic for now. . The maximum rank possible for a matrix is $max(R, C)$ . But an interesting question would be ü§î, what is the minimum rank possible for a matrix, is it 0, is it 1? . Ans: Rank is zero, in case of zero matrix. . Just a leaving thought, if I would have been a developer of Numpy, I would not have allowed np.eye as the method for identity matrix. Better to use np.identity only. üòû . Linear Regression . Considering weight as a linear function of height: . $weight_{1} approx theta_{0} + theta_{1} * height_{1}$ | $weight_{2} approx theta_{0} + theta_{1} * height_{2}$ | $weight_{N} approx theta_{0} + theta_{1} * height_{N}$ | . $$ W_{N times1} = X_{N times2} , theta_{2 times1} $$ where the feature matrix $X$, $X = begin{bmatrix} 1 &amp; height_{1} 1 &amp; height_{2} vdots &amp; vdots 1 &amp; height_{N} end{bmatrix}$ . $ theta_{0}$, Bias/Intercept term : (the value of $y$, when $x$ is set to zero) | $ theta_{1}$, Slope term : (the increase in $y$, when $x$ is increased by 1 unit) | . import gradio as gr weight_height_df = pd.read_csv(&quot;assets/2022-02-17-machine-learning-quiz2-practice/weight-height.csv&quot;) # take 30 points sampled_idx = np.random.choice(np.arange(len(weight_height_df)), size = 30, replace = False) weight_height_df = weight_height_df.iloc[sampled_idx][[&quot;Height&quot;, &quot;Weight&quot;]] display(weight_height_df) def plot_line(theta0, theta1): y = weight_height_df[&quot;Height&quot;] x = weight_height_df[&quot;Weight&quot;] gr.Interface(fn = plot_line, inputs = [&quot;number&quot;, &quot;number&quot;], outputs = gr.outputs.Timeseries(x = live = True).launch() . Height Weight . 601 67.115564 | 168.202167 | . 4738 67.222467 | 176.538232 | . 6375 66.157180 | 162.339164 | . 9129 66.313844 | 139.141991 | . 5347 67.098583 | 160.693330 | . 8963 64.334788 | 161.746797 | . 1393 68.342365 | 187.633463 | . 2241 64.721622 | 150.619457 | . 8061 65.118340 | 146.650334 | . 2494 74.153065 | 212.276328 | . 697 71.434727 | 206.594059 | . 9641 65.858067 | 161.902044 | . 7281 64.624289 | 138.112330 | . 7222 63.126139 | 136.239929 | . 142 66.206032 | 180.889555 | . 651 70.661992 | 217.951883 | . 8070 65.061414 | 131.588929 | . 9735 66.691880 | 151.812907 | . 9520 63.763403 | 136.230864 | . 5421 63.291302 | 126.409991 | . 1327 70.752647 | 202.741657 | . 6761 67.462286 | 156.307311 | . 2209 68.269014 | 196.843334 | . 1523 70.886144 | 224.695162 | . 8818 61.179601 | 130.410229 | . 6839 59.809534 | 109.657437 | . 8359 69.804817 | 174.027459 | . 4692 73.706027 | 231.697887 | . 2473 66.014958 | 169.099038 | . 1993 65.513623 | 173.178827 | . ValueError Traceback (most recent call last) /tmp/ipykernel_2235/1221736475.py in &lt;module&gt; 11 x = weight_height_df[&#34;Weight&#34;] 12 &gt; 13 gr.Interface(fn = plot_line, inputs = [&#34;number&#34;, &#34;number&#34;], live = True).launch() ~/anaconda3/lib/python3.9/site-packages/gradio/interface.py in __init__(self, fn, inputs, outputs, verbose, examples, examples_per_page, live, layout, show_input, show_output, capture_session, interpretation, num_shap, theme, repeat_outputs_per_model, title, description, article, thumbnail, css, height, width, allow_screenshot, allow_flagging, flagging_options, encrypt, show_tips, flagging_dir, analytics_enabled, server_name, server_port, enable_queue, api_mode, flagging_callback) 168 169 self.input_components = [get_input_instance(i) for i in inputs] --&gt; 170 self.output_components = [get_output_instance(o) for o in outputs] 171 if repeat_outputs_per_model: 172 self.output_components *= len(fn) ~/anaconda3/lib/python3.9/site-packages/gradio/interface.py in &lt;listcomp&gt;(.0) 168 169 self.input_components = [get_input_instance(i) for i in inputs] --&gt; 170 self.output_components = [get_output_instance(o) for o in outputs] 171 if repeat_outputs_per_model: 172 self.output_components *= len(fn) ~/anaconda3/lib/python3.9/site-packages/gradio/outputs.py in get_output_instance(iface) 830 return iface 831 else: --&gt; 832 raise ValueError( 833 &#34;Output interface must be of type `str` or `dict` or&#34; 834 &#34;`OutputComponent` but is {}&#34;.format(iface) ValueError: Output interface must be of type `str` or `dict` or`OutputComponent` but is None . from ipywidgets import interact, interactive, fixed, interact_manual import ipywidgets as widgets import matplotlib.pyplot as plt %matplotlib inline import numpy as np def plot_func(freq, val): x = np.linspace(0, 2*np.pi) y = np.sin(x * freq) y2 = np.zeros(x.shape) y2[:] = val plt.plot(x, y2) plt.plot(x, y) interact(plot_func, freq = widgets.FloatSlider(value=7.5, min=1, max=5.0, step=0.5), val = widgets.FloatSlider(value=7.5, min=1, max=5.0, step=0.5)) . &lt;function __main__.plot_func(freq, val)&gt; .",
            "url": "https://yadav-sachin.github.io/blog/mlcourse2022/2022/02/17/machine-learning-quiz2-practice.html",
            "relUrl": "/mlcourse2022/2022/02/17/machine-learning-quiz2-practice.html",
            "date": " ‚Ä¢ Feb 17, 2022"
        }
        
    
  
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "https://yadav-sachin.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://yadav-sachin.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}