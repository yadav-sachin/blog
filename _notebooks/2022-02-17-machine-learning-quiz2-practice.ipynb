{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Quiz 2 Practice\n",
    "- toc: true\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Sachin Yadav\n",
    "- categories: [MLCourse2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#collapse\n",
    "%pip install -q blackcellmagic\n",
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maths for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Given a vector $\\epsilon$, we can calculate $\\sum\\epsilon_{i}^{2}$ using $\\epsilon^{T} \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "# As per the convention we take epsilon to be a 2D column vector\n",
    "y = np.array([1.3, 2.5, 6.4, 8.1, 9.0]).reshape(-1, 1)\n",
    "y_hat = np.array([1.5, 2.0, 5.9, 8.5, 9.0]).reshape(-1, 1)\n",
    "\n",
    "epsilon = np.abs(y - y_hat)\n",
    "\n",
    "epsilon_square_sum1 = np.sum(epsilon**2)\n",
    "epsilon_square_sum2 = (epsilon.T @ epsilon).item()\n",
    "\n",
    "assert np.allclose(epsilon_square_sum1, epsilon_square_sum2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëç works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. $(AB)^{T} = B^{T}A^{T}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "A = np.random.randn(50, 10)\n",
    "B = np.random.randn(10, 20)\n",
    "\n",
    "ab_t = (A @ B).T\n",
    "b_t_a_t = B.T @ A.T\n",
    "assert np.allclose(ab_t, b_t_a_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üôÑ Knew it already!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For a scalar $s$, $s = s^{T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Derivative of scalar $s$ with respect to (yes!, I wrote wrt as full here üòÅ) vector $\\theta$\n",
    "   $$\\theta = \\begin{bmatrix} \\theta_{1} \\\\ \\theta_{2} \\\\ \\vdots \\\\ \\theta{n} \\end{bmatrix}$$\n",
    "    $$\\frac{\\partial s}{\\partial \\theta} = \\begin{bmatrix}\n",
    "     \\frac{\\partial s}{\\partial \\theta_{1}} \\\\\n",
    "     \\frac{\\partial s}{\\partial \\theta_{2}} \\\\\n",
    "     \\frac{\\partial s}{\\partial \\theta_{3}} \\\\\n",
    "     \\vdots \\\\\n",
    "     \\frac{\\partial s}{\\partial \\theta_{n}} \n",
    "     \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. If $A$ is a matrix and $\\theta$ is a vector, and $A\\theta$ is a scalar. Then \n",
    "   $$ \\frac{\\partial A \\theta}{\\partial \\theta} = A^{T} $$\n",
    "\n",
    "ü§î Taking some similarity with $a\\theta$, where both $a$ and $\\theta$ are scalar, I have an idea that it would be A. But shape of gradient would be $N \\times 1$, so $A^{T}$ is my guess before starting any calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "N = 20\n",
    "# as A $\\theta$ is scalar, so A.shape[0] should be 1.\n",
    "A = torch.randn((1, N))\n",
    "theta = torch.randn((N, 1), requires_grad=True)\n",
    "scalar = A @ theta\n",
    "scalar.backward()\n",
    "assert torch.allclose(theta.grad, A.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëç all good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Assume $Z$ is a matrix of form $X^{T}X$, then \n",
    "   $$ \\frac{\\partial (\\theta^{T}Z\\theta)}{\\partial \\theta} = 2Z^{T}\\theta$$\n",
    "\n",
    "ü§î Let me again make a good guess before any calculation, if $\\theta$ and $Z$ are both scaler, then the derivative would look like $2Z\\theta$. So my guess would $2Z\\theta$, which is equal to $2Z^{T}\\theta$ as both are $Z$ is symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapse\n",
    "X = torch.randn((N, N))\n",
    "Z = X.T @ X\n",
    "theta = torch.randn((N, 1), requires_grad=True)\n",
    "\n",
    "scalar = theta.T @ Z @ theta\n",
    "scalar.backward()\n",
    "\n",
    "assert torch.allclose(theta.grad, 2 * Z.T @ theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëç good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's skip over the content of Rank topic for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum rank possible for a matrix is $max(R, C)$ \n",
    "\n",
    "But an interesting question would be ü§î, what is the minimum rank possible for a matrix, is it 0, is it 1?\n",
    "\n",
    "Ans: Rank is zero, in case of zero matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a leaving thought, if I would have been a developer of Numpy, I would not have allowed `np.eye` as the method for identity matrix. Better to use `np.identity` only. üòû"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering `weight` as a linear function of `height`:\n",
    "- $weight_{1} \\approx \\theta_{0} + \\theta_{1} * height_{1}$\n",
    "- $weight_{2} \\approx \\theta_{0} + \\theta_{1} * height_{2}$\n",
    "- $weight_{N} \\approx \\theta_{0} + \\theta_{1} * height_{N}$\n",
    "\n",
    "Add extra columns of $1s$ for the bias term in $\\theta$\n",
    "\n",
    "$$ W_{N\\times1} = X_{N\\times2} \\, \\theta_{2\\times1} $$\n",
    "where the feature matrix $X$, $X = \\begin{bmatrix}\n",
    "1 & height_{1} \\\\\n",
    "1 & height_{2} \\\\\n",
    "\\vdots & \\vdots \\\\\n",
    "1 & height_{N}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "- $\\theta_{0}$, Bias/Intercept term : (the value of $y$, when $x$ is set to zero)\n",
    "- $\\theta_{1}$, Slope term : (the increase in $y$, when $x$ is increased by 1 unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generalized Linear Regression**\n",
    "- $N$: Number of training samples\n",
    "- $M$: Number of features\n",
    "  \n",
    "$$ \\begin{bmatrix}\n",
    "\\hat{y}_{1} \\\\\n",
    "\\hat{y}_{2} \\\\\n",
    "\\vdots \\\\\n",
    "\\hat{y}_{N} \\\\\n",
    "\\end{bmatrix}\n",
    "_{N \\times 1}\n",
    "= \\begin{bmatrix}\n",
    "1 & x_{1, 1} & x_{1, 2} & \\ldots & x_{1, M} \\\\\n",
    "1 & x_{2, 1} & x_{2, 2} & \\ldots & x_{2, M} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ldots & \\vdots \\\\\n",
    "1 & x_{N, 1} & x_{N, 2} & \\ldots & x_{N, M} \\\\\n",
    "\\end{bmatrix} _{N \\times (M + 1)}\n",
    "\\begin{bmatrix}\n",
    "\\theta_{0} \\\\\n",
    "\\theta_{1} \\\\\n",
    "\\vdots \\\\\n",
    "\\theta_{M}\n",
    "\\end{bmatrix} _{(M + 1)\\times 1}\n",
    "$$\n",
    "\n",
    "$$ \\hat{y} = X \\theta $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the task at our hand is to estimate \"good\" values of $\\theta$, which will give \"good\" approximation to the actual values.But how do we decide if a set of values of $\\theta$ is \"better\" than another value of $\\theta$. We need a metric for evalution here.\n",
    "\n",
    "Let $\\epsilon_{i}$ be $y_{i} - \\hat{y}_{i}$, where $\\epsilon_{i} \\sim \\mathcal{N} (0, \\sigma^{2})$. We are assuming that $\\epsilon_{i}$ is coming from this normal distribution.\n",
    "\n",
    "We want $|\\epsilon_{1}|$, $|\\epsilon_{2}|$, $|\\epsilon_{3}|$ ... , $|\\epsilon_{N}|$ to be small.\n",
    "\n",
    "So we can try to minimize L2 norm (Squared Error) or L1 norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc2e0da2aaa43ad9df84200548a9492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-300.0, description='theta0', max=1000.0, min=-1000.0, step=1.0), Floa‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_func(theta0, theta1)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse\n",
    "weight_height_df = pd.read_csv(\n",
    "    \"assets/2022-02-17-machine-learning-quiz2-practice/weight-height.csv\"\n",
    ")\n",
    "# take 30 points\n",
    "sampled_idx = np.random.choice(np.arange(len(weight_height_df)), size=30, replace=False)\n",
    "weight_height_df = weight_height_df.iloc[sampled_idx][[\"Height\", \"Weight\"]].sort_values(\n",
    "    by=[\"Height\"]\n",
    ")\n",
    "\n",
    "\n",
    "def plot_func(theta0, theta1):\n",
    "    x = weight_height_df[\"Height\"]\n",
    "    y = weight_height_df[\"Weight\"]\n",
    "    y_hat = theta0 + x * theta1\n",
    "    fig, ax = plt.subplots(figsize = (10, 8))\n",
    "    ax.scatter(x, y, label=\"Actual\")\n",
    "    ax.plot(x, y_hat, label=\"Pred\", linestyle = \"--\")\n",
    "    ax.legend()\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([50, 400])\n",
    "    mse_val = np.mean((y - y_hat)**2)\n",
    "    ax.set_title(rf\"$\\theta_{0}$={theta0}, $\\theta_{1}$={theta1}    MSE val: {mse_val:.3f}\")\n",
    "\n",
    "\n",
    "interact(\n",
    "    plot_func,\n",
    "    theta0=widgets.FloatSlider(name = \"theta0 (bias)\", value=-300, min=-1000, max=1000, step=1),\n",
    "    theta1=widgets.FloatSlider(name = \"theta1 (slope)\", value=7.5, min=-20, max=20, step=0.01),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note: Run the notebook in Colab to view the interactive plot above, where we manually change parameters (using sliders) and fit the line through training points with Mean Squared error as the guiding value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equation\n",
    "$$ y = X\\theta + \\epsilon$$\n",
    "Objective: To minimize $\\epsilon^{T} \\epsilon$\n",
    "$$\\epsilon^{T} \\epsilon = y y^{T} - 2 y^{T}X\\theta + \\theta^{T}X^{T}X\\theta$$\n",
    "$$\\frac{\\partial (\\epsilon^{T} \\epsilon)}{\\partial \\theta} = -2X^{T}y + 2X^{T}X\\theta$$ \n",
    "(we use some of our results from previous chapter \"Maths for ML\")\n",
    "\n",
    "Setting it to zero, \n",
    "$$ \\theta^{*} = (X^{T}X)^{-1}X^{T}y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d237ae157f8cbaa923dd81e7af592b21f98237404da5d65484215342ef66488a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
